{"title":"L17: Panel regression intro","markdown":{"yaml":{"title":"L17: Panel regression intro"},"headingText":"Preliminaries","containsRefs":false,"markdown":"\n\n\n# Lecture overview\n\nTo make the concepts in these lecture notes (and the next) more concrete, we will apply them to the empirical analysis of whether firm profitability is predictable. To be more specific, we will ask: \n\n**Which of the following firm characteristics (if any) have statistically significant predictive power over firms' profitability: the firm's cash holdings, its book leverage or its capital investments?**\n\nIn this lecture, we will start by collecting the data we need for this analysis and producing some key descriptive statistics of the data. We will then perform a regression analysis where firm future profitability is the dependent variable, and firm cash holdings, book leverage,and investment are the explanatory variables. In this lecture, we will showcase some common practical issues that one needs to be aware of any time they run a regression:\n1. The effect of outliers on our regression results\n2. The difference between economic magnitude and statistical significance\n3. Multicollinearity (highly correlated independent variables)\n\nIn the following lecture, we will continue this analysis by tackling two other very common issues with regression analysis:\n1. The potential presence of \"fixed-effects\" in the data\n2. The issue of correlated error terms in the regression\n\n# The data\n\nThe first step in our analysis is to decide exactly what data we will use to try to answer this question.\n1. We will use the Compustat dataset as raw data (the \"compa.zip\" file in the \"data\" folder). \n\nWe then have to be explicit about exactly how each variable in the analysis will be calculated:\n1. Dependent variable:\n    - roa = net income before extraordinary items (``ib``) divided by total assets (``at``)\n\n2. Independent variables:\n    - cash holdings = cash and cash equivalents (``che``) divided by total assets\n    - book leverage = long-term debt (``dltt``) divided by total assets\n    - capital expenditures = change in net PP\\&E (``ppent``) divided by total assets \n\nNote that all the variables are scaled by some measure of size (total assets). This is to ensure that our regression results are not dominated by large firms. It also helps avoid heteroskedasticity problems (the dollar-amount data for large firms is much more volatile than the data for small firms). \n\n# Descriptive statistics\n\nSummarize the main variables, both winsorized and unwinsorized:\n\nCheck correlations:\n\nWe can take a look at pairwise scatter plots (to visualize these correlations) using ``pd.plotting.scatter_matrix()``:\n\nThese plots help us realize that point-statistics (single numbers) like the correlation between profitability and cash holdings may mask how rich the data truly is and make us believe that patterns in the data (the -0.32 correlation seems quite strong) are more robust than they really are. Always look at your data (plot it). Just make sure you do it after you mitigate the effect of outliers or the images will look very distorted. \n\n# Linear regression\n\nLet's use the non-winsorized data first for our baseline regression:\n\n## The effect of outliers\n\nNow let's use the winsorized variables and look at the difference. Check the coefficient on the investment variable in particular.\n\n## Economic significance vs statistical significance\n\nIt is easy to use the results in the regression output above and decide (based on p-values or t-statistics) if the independent variables have a **statistically** significant relation with the dependent variable. But it is not clear if there relations are large or small in magnitude (does investment have a large impact on future profitability? larger than leverage?). That is what we mean by **economically** significant.\n\nTo help ease the interpretation of these economic magnitudes, we generally standardize all the variables in the regression by subtracting their mean and dividing by their standard deviation (see below). After doing this, the regression coefficient on any independent variable X, will tell us by how many standard deviations we expect the dependent variable Y to move, when the X variable changes by one standard deviation. \n\nSo after the normalization, the X variables with larger coefficients have a larger economic impact on the Y variable.  \n\n## Multicollinearity\n\nOne common way that multicollinearity arises when two or more of your independent variables (X) are very highly correlated (close to 1). The usual way to deal with this issue, is to calculate the correlation matrix between all the variables in your study, to identify which group of variables are highly correlated with each other. Then we simply drop all but one of them from the analysis.\n\nBelow, we artificially create this problem in our example application, by introducing in our regression a variable that equals the leverage variable times 100. This will have a correlation of 1 with the leverage variable. However, as we'll see below, \"statsmodels\" will NOT give us an error. So it's up to us to make sure that we don't have this problem in our data by always looking at the correlation matrix of our data.\n\nNote how the coefficient on ``n_leverage`` has changed. Also, look at Notes [2] above.\n\nMulticollinearity can arise even if a \"linear combination\" (a weighted sum or difference) of our variables is highly correlated with some other variable in the regression. To see this in action, we will add to our explanatory variables, a variable called ``illiquid`` which measures the non-cash assets of the firm (divided by total assets). In this case, the sum of ``cash`` and ``illiquid`` will equal 1 at all times, which is equal to another explanatory variable in our regression: the constant term.\n\nAgain, we did not get an error, but the results above can not be trusted. To see this, you can check Notes [2] above, but you can also print out the correlation matrix. \n\nAgain, dropping one of the problem variables (\"cash\" or \"illiquid\") would solve our problem.\n","srcMarkdownNoYaml":"\n\n# Preliminaries\n\n# Lecture overview\n\nTo make the concepts in these lecture notes (and the next) more concrete, we will apply them to the empirical analysis of whether firm profitability is predictable. To be more specific, we will ask: \n\n**Which of the following firm characteristics (if any) have statistically significant predictive power over firms' profitability: the firm's cash holdings, its book leverage or its capital investments?**\n\nIn this lecture, we will start by collecting the data we need for this analysis and producing some key descriptive statistics of the data. We will then perform a regression analysis where firm future profitability is the dependent variable, and firm cash holdings, book leverage,and investment are the explanatory variables. In this lecture, we will showcase some common practical issues that one needs to be aware of any time they run a regression:\n1. The effect of outliers on our regression results\n2. The difference between economic magnitude and statistical significance\n3. Multicollinearity (highly correlated independent variables)\n\nIn the following lecture, we will continue this analysis by tackling two other very common issues with regression analysis:\n1. The potential presence of \"fixed-effects\" in the data\n2. The issue of correlated error terms in the regression\n\n# The data\n\nThe first step in our analysis is to decide exactly what data we will use to try to answer this question.\n1. We will use the Compustat dataset as raw data (the \"compa.zip\" file in the \"data\" folder). \n\nWe then have to be explicit about exactly how each variable in the analysis will be calculated:\n1. Dependent variable:\n    - roa = net income before extraordinary items (``ib``) divided by total assets (``at``)\n\n2. Independent variables:\n    - cash holdings = cash and cash equivalents (``che``) divided by total assets\n    - book leverage = long-term debt (``dltt``) divided by total assets\n    - capital expenditures = change in net PP\\&E (``ppent``) divided by total assets \n\nNote that all the variables are scaled by some measure of size (total assets). This is to ensure that our regression results are not dominated by large firms. It also helps avoid heteroskedasticity problems (the dollar-amount data for large firms is much more volatile than the data for small firms). \n\n# Descriptive statistics\n\nSummarize the main variables, both winsorized and unwinsorized:\n\nCheck correlations:\n\nWe can take a look at pairwise scatter plots (to visualize these correlations) using ``pd.plotting.scatter_matrix()``:\n\nThese plots help us realize that point-statistics (single numbers) like the correlation between profitability and cash holdings may mask how rich the data truly is and make us believe that patterns in the data (the -0.32 correlation seems quite strong) are more robust than they really are. Always look at your data (plot it). Just make sure you do it after you mitigate the effect of outliers or the images will look very distorted. \n\n# Linear regression\n\nLet's use the non-winsorized data first for our baseline regression:\n\n## The effect of outliers\n\nNow let's use the winsorized variables and look at the difference. Check the coefficient on the investment variable in particular.\n\n## Economic significance vs statistical significance\n\nIt is easy to use the results in the regression output above and decide (based on p-values or t-statistics) if the independent variables have a **statistically** significant relation with the dependent variable. But it is not clear if there relations are large or small in magnitude (does investment have a large impact on future profitability? larger than leverage?). That is what we mean by **economically** significant.\n\nTo help ease the interpretation of these economic magnitudes, we generally standardize all the variables in the regression by subtracting their mean and dividing by their standard deviation (see below). After doing this, the regression coefficient on any independent variable X, will tell us by how many standard deviations we expect the dependent variable Y to move, when the X variable changes by one standard deviation. \n\nSo after the normalization, the X variables with larger coefficients have a larger economic impact on the Y variable.  \n\n## Multicollinearity\n\nOne common way that multicollinearity arises when two or more of your independent variables (X) are very highly correlated (close to 1). The usual way to deal with this issue, is to calculate the correlation matrix between all the variables in your study, to identify which group of variables are highly correlated with each other. Then we simply drop all but one of them from the analysis.\n\nBelow, we artificially create this problem in our example application, by introducing in our regression a variable that equals the leverage variable times 100. This will have a correlation of 1 with the leverage variable. However, as we'll see below, \"statsmodels\" will NOT give us an error. So it's up to us to make sure that we don't have this problem in our data by always looking at the correlation matrix of our data.\n\nNote how the coefficient on ``n_leverage`` has changed. Also, look at Notes [2] above.\n\nMulticollinearity can arise even if a \"linear combination\" (a weighted sum or difference) of our variables is highly correlated with some other variable in the regression. To see this in action, we will add to our explanatory variables, a variable called ``illiquid`` which measures the non-cash assets of the firm (divided by total assets). In this case, the sum of ``cash`` and ``illiquid`` will equal 1 at all times, which is equal to another explanatory variable in our regression: the constant term.\n\nAgain, we did not get an error, but the results above can not be trusted. To see this, you can check Notes [2] above, but you can also print out the correlation matrix. \n\nAgain, dropping one of the problem variables (\"cash\" or \"illiquid\") would solve our problem.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"lecture17_regression_application_panel.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.361","theme":"zephyr","page-layout":"full","grid":{"sidebar-width":"400px"},"title":"L17: Panel regression intro"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}